{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from utils import *\n",
    "import dataset\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import random\n",
    "from model_training import *\n",
    "import neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 666) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.set_deterministic(True)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Project(iliaavilov/Image-captioning)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neptune.init('iliaavilov/Image-captioning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['NEPTUNE_API_TOKEN']=\n",
    "os.environ['NEPTUNE_PROJECT']=\n",
    "os.environ['NEPTUNE_NOTEBOOK_ID']=\n",
    "os.environ['NEPTUNE_NOTEBOOK_PATH']=\"Desktop/Projects/Image_captioning/training.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание файлов для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create_input_files(dataset = 'coco', \n",
    "#                   karpathy_json_path = 'data/dataset_coco.json', \n",
    "#                   image_folder = 'data/',\n",
    "#                   output_folder = 'images/', \n",
    "#                   captions_per_image = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка словарей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('images/WORDMAP_COCO.json') as f:\n",
    "    wordmap = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = dict((v,k) for k,v in wordmap.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wordmap - словарь, каждому слову ставящий в соответствие его позиционный индекс\\\n",
    "res - Обратный к wordmap словарь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка/инициализация модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры модели\n",
    "encoded_image_size = 14\n",
    "vocab_size = len(wordmap)\n",
    "word_embeddings_dim = 512\n",
    "attention_dim = 512\n",
    "decoder_hidden_size = 512\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "checkpoint_name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch, end_epoch, loss_fn, enc, dec, optimizer_encoder, optimizer_decoder = load_models(checkpoint_name, \n",
    "                                                                                              encoded_image_size, \n",
    "                                                                                              word_embeddings_dim, \n",
    "                                                                                              attention_dim,\n",
    "                                                                                              decoder_hidden_size, \n",
    "                                                                                              vocab_size, \n",
    "                                                                                              device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Инициализация загрузчиков данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "workers = 0\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "set_seed()\n",
    "train_loader = torch.utils.data.DataLoader(dataset.CaptionDataset('images/', \n",
    "                                                                  'TRAIN', \n",
    "                                                                  transform=transforms.Compose([normalize])),\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True, \n",
    "                                           num_workers=workers, \n",
    "                                           pin_memory=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset.CaptionDataset('images/',  \n",
    "                                                                'VAL',\n",
    "                                                                transform=transforms.Compose([normalize])),\n",
    "                                         batch_size=200, \n",
    "                                         shuffle=True, \n",
    "                                         num_workers=workers, \n",
    "                                         pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ui.neptune.ai/iliaavilov/Image-captioning/e/IM-23\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Experiment(IM-23)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neptune.create_experiment(name = 'Soft_attention', upload_source_files = ['utils.py', \n",
    "                                                                          'model_training.py', \n",
    "                                                                          'model.py', \n",
    "                                                                          'dataset.py'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "Current loss 9.081635475158691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiencing connection interruptions. Reestablishing communication with Neptune.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss 3.4759562015533447\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, end_epoch):\n",
    "    print('epoch:', epoch)\n",
    "\n",
    "    train(enc, dec, device, loss_fn, train_loader, optimizer_decoder, optimizer_encoder, epoch)\n",
    "    \n",
    "    validate(enc, dec, device, loss_fn, val_loader, wordmap, epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "neptune": {
   "notebookId": "53c1b8bb-9fe1-4125-9310-ef3fdd555e3f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
